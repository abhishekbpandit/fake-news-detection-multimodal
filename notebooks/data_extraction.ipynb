{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabbc2cb-1436-41b2-a97f-2032a4820cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd5d8bf-b01f-4d3e-8e4f-a35235a5945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_drive(file_id, destination_file_name):\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        'credentials.json',\n",
    "        scopes=['https://www.googleapis.com/auth/drive.readonly']\n",
    "    )\n",
    "\n",
    "    drive_service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "                          \n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    file_stream = io.FileIO(destination_file_name, 'wb')\n",
    "    downloader = MediaIoBaseDownload(file_stream, request)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        status, done = downloader.next_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd7b882-e210-47bf-81b6-cc8820df821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tar_bz2(source_file, destination_folder):\n",
    "    with tarfile.open(source_file, 'r:bz2') as tar:\n",
    "        tar.extractall(destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04023553-a1d1-4d11-a818-fe0bc61bf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gcs(bucket_name, source_folder, destination_folder):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    for root, _, files in os.walk(source_folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            blob_name = os.path.join(destination_folder, os.path.relpath(file_path, source_folder))\n",
    "\n",
    "            blob = bucket.blob(blob_name)\n",
    "            blob.upload_from_filename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa778837-02b5-4e2e-a283-95890c449b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gcs(bucket_name, source_file, destination_file):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    blob = bucket.blob(destination_file)\n",
    "    blob.upload_from_filename(source_file)\n",
    "\n",
    "def extract_and_upload_tar_bz2(source_file, destination_folder, bucket_name):\n",
    "    # If the destination folder exists, remove it\n",
    "    if os.path.exists(destination_folder):\n",
    "        shutil.rmtree(destination_folder)\n",
    "\n",
    "    # Create the destination folder\n",
    "    os.makedirs(destination_folder)\n",
    "    \n",
    "    with tarfile.open(source_file, 'r:bz2') as tar:\n",
    "        for member in tar:\n",
    "            if member.isfile():\n",
    "                member.name = os.path.basename(member.name)  # ensure only the file name is kept\n",
    "                tar.extract(member, path=destination_folder)\n",
    "\n",
    "                local_file = os.path.join(destination_folder, member.name)\n",
    "                upload_to_gcs(bucket_name, local_file, member.name)\n",
    "                os.remove(local_file)  # remove the file after upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e2df12-c01a-4c3b-b3bf-d927a46d3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the Google Drive file ID and destination file name for download\n",
    "file_id = '1cjY6HsHaSZuLVHywIxD5xQqng33J5S2b'\n",
    "destination_file_name = 'downloaded_data.tar.bz2'\n",
    "\n",
    "# Provide the GCS bucket name and destination folder path\n",
    "bucket_name = 'fake-news-data'\n",
    "destination_folder = 'fakeddit'\n",
    "\n",
    "# Specify the folder path where the extracted files will be saved\n",
    "extracted_folder = 'extracted_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146d028-6282-480f-a852-6d0376680b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_from_drive(file_id, destination_file_name)\n",
    "extract_and_upload_tar_bz2(destination_file_name, extracted_folder, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e23be6-ddb5-423b-b3c6-84b74fd886c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
